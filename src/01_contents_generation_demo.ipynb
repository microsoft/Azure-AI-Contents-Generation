{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents Generation Demo\n",
    "\n",
    "## シナリオ案\n",
    "- ゲーム用広告生成\n",
    "  - ターゲット：ブログ記事（発売情報、ゲームの魅力・特徴、シリーズものは他との違い、動画・画像データを差し込んだ具体的な説明）\n",
    "  - コンテンツ：タイトル、メタデータ、記事本文\n",
    "  - インプット：\n",
    "\t- 製品情報：公式ページから抽出\n",
    "\t- 動画：Youtubeから取得\n",
    "\t  - https://www.youtube.com/watch?v=PDHvMiX_vwk\n",
    "\t  - https://www.youtube.com/watch?v=eoIWH1p9LfM\n",
    "\t- その他情報：\n",
    "\t  - Webページ：公式ページから画像データなど抽出\n",
    "\t- ユーザプロンプト：内容の指示・カスタマイズ\n",
    "  - アウトプット形式\n",
    "\t- マークダウン\n",
    "- ブランドガイドライン（ブランドのイメージ、方針）に沿ったゲーム用広告生成\n",
    "  - 過去の製品説明、画像、動画\n",
    "    - 利用目的は、近いデータセットをひっぱってきて、\n",
    "    \t- 過去の成功体験をトレースする\n",
    "    \t- 製品ラインのイメージを遵守する（例：ドラクエシリーズの世界観）\n",
    "    - これは事前にインデックス化しておく\n",
    "    - 既存のWebページなどあれば、情報として使えるためインプットさせる\n",
    " \n",
    "## Architecture Overview\n",
    "- 動画データの前処理：\n",
    "  - 動画データから情報を抽出するために、フレーム画像に分割してGPT-4oでキャプション生成。\n",
    "  - キャプションはJsonメタデータで一括管理。コンテンツ生成時に目的の画像データを検索するのに利用する。\n",
    "- PDF（画像とテキスト）の前処理：\n",
    "  - PDFデータから情報を抽出するために、Document Intelligence を利用する。画像の抽出と階層化形式（マークダウン形式）でのアウトプットが可能。\n",
    "  - 画像データはGPT-4oでキャプションを生成して、Jsonメタデータで一括管理。コンテンツ生成時に目的の画像データを検索するのに利用する。\n",
    "- コンテンツ生成\n",
    "  - Jsonメタデータとテキストデータをコンテキストとしてすべてプロンプトに含める。\n",
    "  - 出力形式は特に指定せず、ブログ用の記事で興味をひく記事で作成するようにだけ指示。\n",
    "- ブランドイメージに沿ったコンテンツ生成\n",
    "  - 目的のコンテンツに合致させるために、アウトプットに関する情報を追加する。\n",
    "  - ここでは、過去のブログ記事（Webページを想定）のイメージに近いものを作成させるために、情報を抽出。\n",
    "    - 情報抽出はBeautifulSoupでクローリング\n",
    "\n",
    "## Roadmap\n",
    "- ブランドガイドライン、過去の広告データなどを検索インデックス化して、RAGのアーキテクチャを追加\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from azure.ai.documentintelligence import DocumentIntelligenceClient\n",
    "from azure.ai.documentintelligence.models import ContentFormat\n",
    "from preprocessing.preprocessing_with_image import analyze_layout\n",
    "\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.indexes import SearchIndexClient, SearchIndexerClient\n",
    "from azure.search.documents.indexes.models import (\n",
    "    AIServicesVisionParameters,\n",
    "    AIServicesVisionVectorizer,\n",
    "    AIStudioModelCatalogName,\n",
    "    AzureMachineLearningVectorizer,\n",
    "    AzureOpenAIVectorizer,\n",
    "    AzureOpenAIModelName,\n",
    "    AzureOpenAIParameters,\n",
    "    BlobIndexerDataToExtract,\n",
    "    BlobIndexerParsingMode,\n",
    "    CognitiveServicesAccountKey,\n",
    "    DefaultCognitiveServicesAccount,\n",
    "    ExhaustiveKnnAlgorithmConfiguration,\n",
    "    ExhaustiveKnnParameters,\n",
    "    FieldMapping,\n",
    "    HnswAlgorithmConfiguration,\n",
    "    HnswParameters,\n",
    "    IndexerExecutionStatus,\n",
    "    IndexingParameters,\n",
    "    IndexingParametersConfiguration,\n",
    "    InputFieldMappingEntry,\n",
    "    OutputFieldMappingEntry,\n",
    "    ScalarQuantizationCompressionConfiguration,\n",
    "    ScalarQuantizationParameters,\n",
    "    SearchField,\n",
    "    SearchFieldDataType,\n",
    "    SearchIndex,\n",
    "    SearchIndexer,\n",
    "    SearchIndexerDataContainer,\n",
    "    SearchIndexerDataIdentity,\n",
    "    SearchIndexerDataSourceConnection,\n",
    "    SearchIndexerSkillset,\n",
    "    SemanticConfiguration,\n",
    "    SemanticField,\n",
    "    SemanticPrioritizedFields,\n",
    "    SemanticSearch,\n",
    "    SimpleField,\n",
    "    VectorSearch,\n",
    "    VectorSearchAlgorithmKind,\n",
    "    VectorSearchAlgorithmMetric,\n",
    "    VectorSearchProfile,\n",
    "    VisionVectorizeSkill\n",
    ")\n",
    "from azure.search.documents.models import (\n",
    "    HybridCountAndFacetMode,\n",
    "    HybridSearch,\n",
    "    SearchScoreThreshold,\n",
    "    VectorizableTextQuery,\n",
    "    VectorizableImageBinaryQuery,\n",
    "    VectorizableImageUrlQuery,\n",
    "    VectorSimilarityThreshold,\n",
    ")\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Image, display, HTML\n",
    "from openai import AzureOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Configuration\n",
    "AZURE_AI_VISION_API_KEY = os.getenv(\"AZURE_AI_VISION_API_KEY\") # Option: For Image Embedding: https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/concept-image-retrieval\n",
    "AZURE_AI_VISION_ENDPOINT = os.getenv(\"AZURE_AI_VISION_ENDPOINT\") # Option: For Image Embedding: https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/concept-image-retrieval\n",
    "AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "AZURE_OPENAI_API_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "BLOB_CONNECTION_STRING = os.getenv(\"BLOB_CONNECTION_STRING\")\n",
    "BLOB_CONTAINER_NAME = os.getenv(\"BLOB_CONTAINER_NAME\")\n",
    "AZURE_SEARCH_ADMIN_KEY = os.getenv(\"AZURE_SEARCH_ADMIN_KEY\") # Option: For Retrievar on RAG\n",
    "AZURE_SEARCH_ENDPOINT = os.getenv(\"AZURE_SEARCH_ENDPOINT\") # Option: For Retrievar on RAG\n",
    "AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT = os.getenv(\"AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT\")\n",
    "AZURE_DOCUMENT_INTELLIGENCE_KEY = os.getenv(\"AZURE_DOCUMENT_INTELLIGENCE_KEY\")\n",
    "aoai_deployment_name = 'gpt-4o' # your model deployment name for GPT-4o\n",
    "aoai_api_version = '2024-02-01' # this might change in the future"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting frames from video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option: To use blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell is optional if you want to use blob storage for image input of gpt-4o. \n",
    "from azure.storage.blob import BlobServiceClient, BlobClient, generate_blob_sas, BlobSasPermissions\n",
    "import datetime\n",
    "\n",
    "# Setting for Azure Blob Storage\n",
    "blob_service_client = BlobServiceClient.from_connection_string(BLOB_CONNECTION_STRING)\n",
    "\n",
    "def upload_to_blob(file_path, blob_name):\n",
    "    blob_client = blob_service_client.get_blob_client(container=BLOB_CONTAINER_NAME, blob=blob_name)\n",
    "    with open(file_path, \"rb\") as data:\n",
    "        blob_client.upload_blob(data, overwrite=True)\n",
    "    \n",
    "    start_time = datetime.datetime.now(datetime.timezone.utc)\n",
    "    expiry_time = start_time + datetime.timedelta(days=7)\n",
    "    \n",
    "    sas_token = generate_blob_sas(\n",
    "        account_name=blob_client.account_name,\n",
    "        container_name=blob_client.container_name,\n",
    "        blob_name=blob_client.blob_name,\n",
    "        account_key=blob_service_client.credential.account_key,\n",
    "        permission=BlobSasPermissions(read=True),\n",
    "        expiry=expiry_time,\n",
    "        start=start_time\n",
    "    )\n",
    "    blob_url = blob_client.url\n",
    "    return blob_url, sas_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note: The openai-python library support for Azure OpenAI is in preview.\n",
    "#Note: This code sample requires OpenAI Python library version 1.0.0 or higher.\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "import json\n",
    "\n",
    "\n",
    "def create_caption_by_gpt(image_url):\n",
    "\t# print(\"Image URL:\", image_url)\n",
    "\tprint(\"Generating caption using GPT-4o model...\")\n",
    "\tclient = AzureOpenAI(\n",
    "\t\tazure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"), \n",
    "\t\tapi_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),  \n",
    "\t\tapi_version=\"2024-02-01\"\n",
    "\t)\n",
    "\n",
    "\tsystem_message = \"\"\"\n",
    "\tYou are an excellent caption creator. You must create a detailed caption for the image below with a maximum of 100 characters.\n",
    "\tThe created caption will be used to describe the image in the search index.\n",
    "\t\"\"\"\n",
    "\n",
    "\tmessage_text = [\n",
    "\t\t{\"role\":\"system\",\"content\":system_message},\n",
    "\t\t{\"role\":\"user\",\"content\": [\n",
    "\t\t\t{\n",
    "\t\t\t\t\"type\": \"text\",\n",
    "\t\t\t\t\"content\": f\"Please provide a caption for the image.\"\n",
    "\t\t\t},\n",
    "\t\t\t{ \n",
    "\t\t\t\t\"type\": \"image_url\",\n",
    "\t\t\t\t\"image_url\": {\n",
    "\t\t\t\t\t\"url\": image_url\n",
    "\t\t\t\t}\n",
    "\t\t\t}\n",
    "\t\t]}\n",
    "\t]\n",
    "\n",
    "\tcompletion = client.chat.completions.create(\n",
    "\t\tmodel=\"gpt-4o\", # model = \"deployment_name\"\n",
    "\t\tmessages = message_text,\n",
    "\t\ttemperature=0,\n",
    "\t\tmax_tokens=200,\n",
    "\t\ttop_p=0.95,\n",
    "\t\tfrequency_penalty=0,\n",
    "\t\tpresence_penalty=0,\n",
    "\t\tstop=None\n",
    "\t\t)\n",
    "\tprint(completion.choices[0].message.content)\n",
    "\treturn completion.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from mimetypes import guess_type\n",
    "\n",
    "# Function to encode a local image into data URL \n",
    "def local_image_to_data_url(image_path):\n",
    "    # Guess the MIME type of the image based on the file extension\n",
    "    mime_type, _ = guess_type(image_path)\n",
    "    if mime_type is None:\n",
    "        mime_type = 'application/octet-stream'  # Default MIME type if none is found\n",
    "\n",
    "    # Read and encode the image file\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        base64_encoded_data = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "    # Construct the data URL\n",
    "    return f\"data:{mime_type};base64,{base64_encoded_data}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import base64\n",
    "import json\n",
    "\n",
    "def extract_frames(video_path, output_dir, interval=5):\n",
    "    # Get the video file name\n",
    "    video_filename = os.path.basename(video_path)\n",
    "    \n",
    "    # Create the output directory\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    # Load the video file\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    duration = frame_count / fps\n",
    "    \n",
    "    # List to save metadata\n",
    "    metadata = []\n",
    "\n",
    "    # Extract frames\n",
    "    frame_number = 0\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        current_time = frame_number / fps\n",
    "        if current_time % interval < 1.0 / fps:\n",
    "            # Save the frame as an image\n",
    "            frame_filename = f\"{video_filename}_frame_{frame_number}.jpg\"\n",
    "            frame_filepath = os.path.join(output_dir, frame_filename)\n",
    "            cv2.imwrite(frame_filepath, frame)\n",
    "            \n",
    "            data_url = local_image_to_data_url(frame_filepath)\n",
    "            \n",
    "            # Generate a caption for the frame image\n",
    "            caption = create_caption_by_gpt(data_url)\n",
    "            \n",
    "            # Save the metadata\n",
    "            metadata.append({\n",
    "                'video_filename': video_filename,\n",
    "                'frame_filename': frame_filename,\n",
    "                'frame_filepath': frame_filepath,\n",
    "                'frame_number': frame_number,\n",
    "                'timestamp': current_time,\n",
    "                'caption': caption\n",
    "            })\n",
    "        \n",
    "        frame_number += 1\n",
    "\n",
    "    # Save metadata as a JSON\n",
    "    metadata_json_path = os.path.join(output_dir, f\"{video_filename}_metadata.json\")\n",
    "    with open(metadata_json_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(metadata, f, ensure_ascii=False, indent=4)\n",
    "    \n",
    "    # Release resources\n",
    "    cap.release()\n",
    "    print(f\"Frames and metadata have been saved in {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the video file\n",
    "video_path = '../data/01_scenario/video/dq3_intro.mp4'\n",
    "output_dir = '../data/01_scenario/video_frames'\n",
    "extract_frames(video_path, output_dir, interval=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting images and document from pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "input_file = \"../data/01_scenario/pdf/dq3.pdf\"\n",
    "output_dir_images = \"../data/01_scenario/images\"\n",
    "output_dir_documents = \"../data/01_scenario/text\"\n",
    "os.makedirs(output_dir_images, exist_ok=True)\n",
    "os.makedirs(output_dir_documents, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_content = analyze_layout(\n",
    "    input_file,\n",
    "   \toutput_dir_images,\n",
    "    AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT,\n",
    "    AZURE_DOCUMENT_INTELLIGENCE_KEY,\n",
    "    AZURE_OPENAI_ENDPOINT,\n",
    "    AZURE_OPENAI_API_KEY,\n",
    "    aoai_deployment_name,\n",
    "    aoai_api_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{output_dir_documents}/{os.path.splitext(os.path.basename(input_file))[0]}.md\", 'w', encoding='utf-8') as f:\n",
    "\tf.write(md_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "images_dir = \"../data/01_scenario/images\"\n",
    "file_paths = glob.glob(os.path.join(f\"{images_dir}/*\"), recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "images_dir = \"../data/01_scenario/images\"\n",
    "file_paths = glob.glob(os.path.join(f\"{images_dir}/*\"), recursive=True)\n",
    "\n",
    "metadata = []\n",
    "\n",
    "for file in file_paths:\n",
    "\tdata_url = local_image_to_data_url(file)\n",
    "\tcaption = create_caption_by_gpt(data_url)\n",
    "\n",
    "\t# Save the metadata\n",
    "\tmetadata.append({\n",
    "\t\t'image_filepath': file,\n",
    "\t\t'caption': caption\n",
    "\t})\n",
    " \n",
    "metadata_json_path = os.path.join(images_dir, f\"images_metadata.json\")\n",
    "with open(metadata_json_path, 'w', encoding='utf-8') as f:\n",
    "\tjson.dump(metadata, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating contents by GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define the root directory\n",
    "root_dir = \"../data/01_scenario\"\n",
    "\n",
    "# Initialize the GPT prompt\n",
    "gpt_prompt = \"\"\n",
    "\n",
    "# Iterate over the subdirectories in the root directory\n",
    "for subdir, dirs, files in os.walk(root_dir):\n",
    "    # Iterate over the files in each subdirectory\n",
    "    for file in files:\n",
    "        # Get the file extension\n",
    "        file_ext = os.path.splitext(file)[1]\n",
    "        \n",
    "        # Check if the file extension is json or md\n",
    "        if file_ext == \".json\" or file_ext == \".md\":\n",
    "            # Read the contents of the file\n",
    "            file_path = os.path.join(subdir, file)\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                file_contents = f.read()\n",
    "            \n",
    "            # Add the structured file information to the GPT prompt\n",
    "            gpt_prompt += f\"File Path: {file_path}\\n\"\n",
    "            gpt_prompt += f\"File Name: {file}\\n\"\n",
    "            gpt_prompt += f\"File Extension: {file_ext}\\n\"\n",
    "            gpt_prompt += \"File Contents:\\n\"\n",
    "            gpt_prompt += file_contents + \"\\n\\n\"\n",
    "\n",
    "# Print the GPT prompt\n",
    "print(gpt_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note: The openai-python library support for Azure OpenAI is in preview.\n",
    "#Note: This code sample requires OpenAI Python library version 1.0.0 or higher.\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "import json\n",
    "\n",
    "\n",
    "client = AzureOpenAI(\n",
    "\tazure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"), \n",
    "\tapi_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),  \n",
    "\tapi_version=\"2024-02-01\"\n",
    ")\n",
    "\n",
    "system_message = f\"\"\"\n",
    "You are an excellent marketing content creator.\n",
    "From the context you are given, create marketing content that best fits your objectives.\n",
    "You must answer in Japanese.\n",
    "\n",
    "# Context\n",
    "{gpt_prompt}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "message_text = [\n",
    "\t{\"role\":\"system\",\"content\":system_message},\n",
    "\t{\"role\":\"user\",\"content\": [\n",
    "\t\t{\n",
    "\t\t\t\"type\": \"text\",\n",
    "\t\t\t\"content\": f\"ゲームのブログ記事を作ってほしいです。ユーザが購入しプレイしたいと思える魅力的なブログ記事を必ず日本語で作成してください。記事には、発売情報、ゲームの魅力・特徴、シリーズものは他との違い、動画・画像データを差し込んだ具体的な説明を含めてください。\"\n",
    "\t\t}\n",
    "\t]}\n",
    "]\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "\tmodel=\"gpt-4o\", # model = \"deployment_name\"\n",
    "\tmessages = message_text,\n",
    "\ttemperature=0,\n",
    "\t# max_tokens=200,\n",
    "\ttop_p=0.95,\n",
    "\tfrequency_penalty=0,\n",
    "\tpresence_penalty=0,\n",
    "\tstop=None\n",
    "\t)\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate contents with brand image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def analyze_website(url):\n",
    "    # Fetch the page\n",
    "    response = requests.get(url)\n",
    "    html_content = response.content\n",
    "\n",
    "    # Parse the HTML using BeautifulSoup\n",
    "    soup = BeautifulSoup(html_content, 'html5lib')\n",
    "\n",
    "    # Get the page title\n",
    "    title = soup.title.string if soup.title else \"No title found\"\n",
    "\n",
    "    # Retrieve metadata\n",
    "    meta_description = soup.find('meta', attrs={'name': 'description'})\n",
    "    meta_keywords = soup.find('meta', attrs={'name': 'keywords'})\n",
    "    meta_description_content = meta_description['content'] if meta_description else \"No description meta tag found\"\n",
    "    meta_keywords_content = meta_keywords['content'] if meta_keywords else \"No keywords meta tag found\"\n",
    "\n",
    "    # Retrieve images\n",
    "    images = [img['src'] for img in soup.find_all('img') if 'src' in img.attrs]\n",
    "\n",
    "    # Retrieve links\n",
    "    # links = [a['href'] for a in soup.find_all('a') if 'href' in a.attrs]\n",
    "\n",
    "    # Retrieve videos\n",
    "    videos = [video['src'] for video in soup.find_all('video') if 'src' in video.attrs]\n",
    "\n",
    "    # Retrieve header information\n",
    "    headers = {}\n",
    "    for level in range(1, 7):\n",
    "        headers[f'h{level}'] = [header.get_text(strip=True) for header in soup.find_all(f'h{level}')]\n",
    "\n",
    "    # Get the page text\n",
    "    page_text = soup.get_text()\n",
    "\n",
    "    # Format results in Markdown\n",
    "    markdown = f\"\"\"\n",
    "\t# Website Analysis Report\n",
    "\n",
    "\t## URL\n",
    "\t{url}\n",
    "\n",
    "\t## Title\n",
    "\t{title}\n",
    "\n",
    "\t## Meta Description\n",
    "\t{meta_description_content}\n",
    "\n",
    "\t## Meta Keywords\n",
    "\t{meta_keywords_content}\n",
    "\n",
    "\t## Images\n",
    "\t{' '.join(images)}\n",
    "\n",
    "\t## Videos\n",
    "\t{' '.join(videos)}\n",
    "\n",
    "\t## Headers\n",
    "\t\"\"\"\n",
    "    for level in range(1, 7):\n",
    "        markdown += f\"\\n### h{level} Headers\\n\"\n",
    "        markdown += '\\n'.join(headers[f'h{level}']) + '\\n'\n",
    "\n",
    "    markdown += f\"\\n## Page Text (First 1000 characters)\\n{page_text[:1000]}\"\n",
    "\n",
    "    # Save HTML content to a file\n",
    "    with open(\"website_content.html\", \"wb\") as file:\n",
    "        file.write(html_content)\n",
    "\n",
    "    return markdown\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "url = \"https://www.famitsu.com/news/202401/16330797.html\"\n",
    "report = analyze_website(url)\n",
    "\n",
    "# Save the Markdown report to a file\n",
    "with open(\"website_report.md\", \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(report)\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_text_file(filepath):\n",
    "    # Load HTML content from a file\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as file:\n",
    "        content = file.read()\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note: The openai-python library support for Azure OpenAI is in preview.\n",
    "#Note: This code sample requires OpenAI Python library version 1.0.0 or higher.\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "import json\n",
    "\n",
    "\n",
    "client = AzureOpenAI(\n",
    "\tazure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"), \n",
    "\tapi_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),  \n",
    "\tapi_version=\"2024-02-01\"\n",
    ")\n",
    "\n",
    "system_message = f\"\"\"\n",
    "You are an excellent marketing content creator.\n",
    "From the context you are given, create marketing content that best fits your objectives.\n",
    "Also, the reference article given is a very good article, so please refer to it in terms of structure, tone, and image citations.\n",
    "You must create natural and engaging content that will attract users to the website.\n",
    "You must answer in Japanese.\n",
    "\n",
    "# Context\n",
    "{gpt_prompt}\n",
    "\n",
    "# Reference Web page Content\n",
    "{load_text_file(\"website_report.md\")}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "message_text = [\n",
    "\t{\"role\":\"system\",\"content\":system_message},\n",
    "\t{\"role\":\"user\",\"content\": [\n",
    "\t\t{\n",
    "\t\t\t\"type\": \"text\",\n",
    "\t\t\t\"content\": f\"ゲームのブログ記事を作ってほしいです。ユーザが購入しプレイしたいと思える魅力的なブログ記事を必ず日本語で作成してください。記事には、発売情報、ゲームの魅力・特徴、シリーズものは他との違い、動画・画像データを差し込んだ具体的な説明を含めてください。ただし、ブログ記事に役に立たない動画・画像データ（Webページの単なるアイコンなど）は含めないでください。\"\n",
    "\t\t}\n",
    "\t]}\n",
    "]\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "\tmodel=\"gpt-4o\", # model = \"deployment_name\"\n",
    "\tmessages = message_text,\n",
    "\ttemperature=0,\n",
    "\t# max_tokens=200,\n",
    "\ttop_p=0.95,\n",
    "\tfrequency_penalty=0,\n",
    "\tpresence_penalty=0,\n",
    "\tstop=None\n",
    "\t)\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improve user prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"\"\"\n",
    "I need a blog post about a game that will make readers want to purchase and play it. The blog post must be written in Japanese and should include the following elements:\n",
    "\n",
    "1. Release information: Provide details about the game's release date, platforms, and any special editions available.\n",
    "2. Game appeal and features: Highlight the unique aspects and attractions of the game. Explain what makes it stand out and why it's worth playing.\n",
    "3. Differences from previous titles (if it’s part of a series): Compare it with other titles in the series, focusing on improvements, new features, and any changes that make this game unique.\n",
    "4. Detailed explanations with multimedia: Include specific descriptions with embedded videos and images to illustrate the gameplay, graphics, and other notable features. Avoid including irrelevant multimedia content like website icons.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note: The openai-python library support for Azure OpenAI is in preview.\n",
    "#Note: This code sample requires OpenAI Python library version 1.0.0 or higher.\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "import json\n",
    "\n",
    "\n",
    "client = AzureOpenAI(\n",
    "\tazure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"), \n",
    "\tapi_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),  \n",
    "\tapi_version=\"2024-02-01\"\n",
    ")\n",
    "\n",
    "system_message = f\"\"\"\n",
    "You are an excellent marketing content creator.\n",
    "From the context you are given, create marketing content that best fits your objectives.\n",
    "Also, the reference article given is a very good article, so please refer to it in terms of structure, tone, and image citations.\n",
    "You must create natural and engaging content that will attract users to the website.\n",
    "You must answer in Japanese.\n",
    "\n",
    "# Context\n",
    "{gpt_prompt}\n",
    "\n",
    "# Reference Web page Content\n",
    "{load_text_file(\"website_report.md\")}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "message_text = [\n",
    "\t{\"role\":\"system\",\"content\":system_message},\n",
    "\t{\"role\":\"user\",\"content\": [\n",
    "\t\t{\n",
    "\t\t\t\"type\": \"text\",\n",
    "\t\t\t\"content\": user_prompt\n",
    "\t\t}\n",
    "\t]}\n",
    "]\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "\tmodel=\"gpt-4o\", # model = \"deployment_name\"\n",
    "\tmessages = message_text,\n",
    "\ttemperature=0,\n",
    "\t# max_tokens=200,\n",
    "\ttop_p=0.95,\n",
    "\tfrequency_penalty=0,\n",
    "\tpresence_penalty=0,\n",
    "\tstop=None\n",
    "\t)\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Description for images in blog post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note: The openai-python library support for Azure OpenAI is in preview.\n",
    "#Note: This code sample requires OpenAI Python library version 1.0.0 or higher.\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "import json\n",
    "\n",
    "\n",
    "def create_detail_descripton_by_gpt(image_url):\n",
    "\t# print(\"Image URL:\", image_url)\n",
    "\tprint(\"Generating caption using GPT-4o model...\")\n",
    "\tclient = AzureOpenAI(\n",
    "\t\tazure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"), \n",
    "\t\tapi_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),  \n",
    "\t\tapi_version=\"2024-02-01\"\n",
    "\t)\n",
    "\n",
    "\tsystem_message = \"\"\"\n",
    "\tYou are an excellent blog post creator. You must create a detailed explanation for blog post.\n",
    "\tThe description must be attractive to the reader, not merely a visual description. This description is to be incorporated directly into the blog, so please keep the text natural.\n",
    "\tIf you determine that the image description does not have a positive impact on the blog, return an empty string.\n",
    "\tYou must answer in Japanese.\n",
    "\t\"\"\"\n",
    "\n",
    "\tmessage_text = [\n",
    "\t\t{\"role\":\"system\",\"content\":system_message},\n",
    "\t\t{\"role\":\"user\",\"content\": [\n",
    "\t\t\t{\n",
    "\t\t\t\t\"type\": \"text\",\n",
    "\t\t\t\t\"content\": f\"Please provide a caption for the image.\"\n",
    "\t\t\t},\n",
    "\t\t\t{ \n",
    "\t\t\t\t\"type\": \"image_url\",\n",
    "\t\t\t\t\"image_url\": {\n",
    "\t\t\t\t\t\"url\": image_url\n",
    "\t\t\t\t}\n",
    "\t\t\t}\n",
    "\t\t]}\n",
    "\t]\n",
    "\n",
    "\tcompletion = client.chat.completions.create(\n",
    "\t\tmodel=\"gpt-4o\", # model = \"deployment_name\"\n",
    "\t\tmessages = message_text,\n",
    "\t\ttemperature=0,\n",
    "\t\t# max_tokens=200,\n",
    "\t\ttop_p=0.95,\n",
    "\t\tfrequency_penalty=0,\n",
    "\t\tpresence_penalty=0,\n",
    "\t\tstop=None\n",
    "\t\t)\n",
    "\tprint(completion.choices[0].message.content)\n",
    "\treturn completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "original_md = completion.choices[0].message.content\n",
    "\n",
    "# Regular expression to extract image and caption\n",
    "figure_pattern = re.compile(r'(<figure>.*?<img src=\"(.*?)\".*?alt=\"(.*?)\".*?<figcaption>(.*?)</figcaption>.*?</figure>)', re.DOTALL)\n",
    "\n",
    "# Markdown text after replacement\n",
    "new_md = original_md\n",
    "\n",
    "# Process each image and caption\n",
    "for match in figure_pattern.findall(original_md):\n",
    "    full_figure, img_src, alt_text, figcaption = match\n",
    "    print(img_src)\n",
    "    \n",
    "    detailed_description = create_detail_descripton_by_gpt(local_image_to_data_url(img_src))\n",
    "    \n",
    "    # New content for the replaced figure block\n",
    "    new_figure_block = f\"\"\"\n",
    "<figure>\n",
    "<img src=\"{img_src}\" alt=\"{alt_text}\">\n",
    "<figcaption>{figcaption}</figcaption>\n",
    "<p>{detailed_description}</p>\n",
    "</figure>\n",
    "\"\"\"\n",
    "    # Replacing the original figure block with the new content\n",
    "    new_md = new_md.replace(full_figure, new_figure_block)\n",
    "\n",
    "print(new_md)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
